

# Semantic Search with AstraDB | NLP & RAG Project

ğŸ“‚ **Skills Highlighted:** NLP Â· RAG Â· Vector Databases Â· MMR Â· Prompt Engineering Â· LLMs

---

## ğŸ“˜ Project Overview

This project demonstrates a complete **semantic search pipeline** using **Retrieval-Augmented Generation (RAG)**. It integrates **AstraDB** for vector storage, uses **Maximal Marginal Relevance (MMR)** for reranking, and applies **LLMs** to generate accurate, context-aware responses from unstructured PDF content.

---

## ğŸ”§ Tech Stack & Tools

* ğŸ **Python**
* ğŸ”— **LangChain**
* ğŸ—ƒ **AstraDB Vector Store** (via **CassIO**)
* ğŸ§  **LLMs** (OpenAI, Gemini via LangChain)
* ğŸ§¬ **Sentence Transformers** (HuggingFace)
* ğŸ“Š **MMR Retrieval** (via LangChain retrievers)

---

## ğŸ” Pipeline Overview

```
PDF ğŸ“„  
   â†“  
Chunking âœ‚ï¸ (Semantic-based)  
   â†“  
Embedding ğŸ§¬ (Sentence Transformers)  
   â†“  
AstraDB ğŸ—ƒ (Vector Store with CassIO)  
   â†“  
MMR Retrieval ğŸª„ (Maximal Marginal Relevance)  
   â†“  
RetrievalQA Chain ğŸ” (LangChain-based pipeline)  
   â†“  
Manual Prompting with LLM ğŸ§   
   â†“  
Final Output: Displayed Answer âœ…
```

---

## ğŸ§© Key Pipeline Components

| Step                  | Description                                                                |
| --------------------- | -------------------------------------------------------------------------- |
| ğŸ“„ **PDF Ingestion**  | Extracts content from multi-page PDF files                                 |
| âœ‚ï¸ **Chunking**       | Splits text into semantically meaningful chunks                            |
| ğŸ§¬ **Embedding**      | Converts chunks into dense vectors using `sentence-transformers`           |
| ğŸ—ƒ **Vector Storage** | Stores embeddings and metadata in AstraDB with CassIO                      |
| ğŸª„ **MMR Retrieval**  | Retrieves diverse and relevant chunks using Maximal Marginal Relevance     |
| ğŸ” **RetrievalQA**    | Combines retriever and LLM to generate context-rich answers                |
| ğŸ§  **LLM Prompting**  | Custom manual prompts crafted for specific, high-quality LLM responses     |
| âœ… **Output Display**  | Final response is printed/displayed to the user based on retrieved context |

---

## ğŸ“Œ Highlights & Capabilities

* âœ… **End-to-end RAG pipeline** from raw documents to LLM-based answers
* âœ… **Semantic chunking** for improved context and relevance
* âœ… **AstraDB + CassIO integration** for efficient vector search
* âœ… **MMR reranking** for balanced, diverse retrieval
* âœ… **RetrievalQA and Prompt Engineering** for high-quality answers


