# -Semantic-Search-with-AstraDB-NLP-RAG-Project

ğŸ“‚ Skills Highlighted: NLP Â· RAG Â· Vector Databases Â· BM25 Â· Prompt Engineering Â· LLMs

ğŸ“˜ Project Overview
This project showcases a complete semantic search pipeline powered by Retrieval-Augmented Generation (RAG). It leverages AstraDB as a vector store, integrates BM25/MMR reranking, and utilizes LLMs to generate context-aware responses â€” with the final output rendered into a professional DOCX report.

ğŸ”§ Tech Stack & Tools
Python

LangChain

AstraDB (Vector Store) + CassIO

Sentence Transformers (HuggingFace)

BM25 & MMR Reranking

LLMs (e.g., OpenAI/Gemini via LangChain)

python-docx for Report Generation

ğŸ§© Key Pipeline Components
Step	Description
ğŸ“„ PDF Ingestion	Parse and extract content from multi-page PDFs
âœ‚ï¸ Chunking	Perform semantic chunking for better context retention
ğŸ§¬ Embedding	Generate vector embeddings using Sentence Transformers
ğŸ—ƒ Vector Storage	Store embeddings and metadata in AstraDB
ğŸ” Retrieval	Retrieve relevant chunks using HNSW-based vector search
ğŸª„ Reranking	Enhance relevance and diversity with BM25 or MMR
ğŸ§  LLM Prompting	Use contextually rich prompts to query LLMs
ğŸ“„ DOCX Output	Generate final answers and save them as a DOCX report

ğŸ“Œ Highlights & Capabilities
âœ… End-to-end RAG pipeline from data ingestion to response generation

âœ… Semantic chunking for improved retrieval relevance

âœ… Integration of modern vector store (AstraDB) with efficient indexing

âœ… Reranking using BM25 and MMR for diverse, high-quality results

âœ… Final output rendered in a structured Word document

ğŸ’¡ This project demonstrates how to combine vector databases, semantic embeddings, and LLMs for intelligent document retrieval and generation workflows.
